<html lang="en-US" prefix="og: http://ogp.me/ns#">
<head>
<meta charset="utf-8"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="https://machinelearningmastery.com/xmlrpc.php" rel="pingback"/>
<!--  Mobile viewport scale -->
<meta content="initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" name="viewport"/>
<!-- This site is optimized with the Yoast SEO plugin v9.2.1 - https://yoast.com/wordpress/plugins/seo/ -->
<title>Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</title>
<link href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" rel="canonical"/>
<link href="https://plus.google.com/u/0/b/117073416089354242117/+MachinelearningmasteryHome/" rel="publisher"/>
<meta content="en_US" property="og:locale"/>
<meta content="article" property="og:type"/>
<meta content="Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation" property="og:title"/>
<meta content="The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods. This architecture is very new, having only been pioneered in 2014, although, has been adopted as the core technology inside Google’s translate service. In this post, you will discover …" property="og:description"/>
<meta content="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" property="og:url"/>
<meta content="Machine Learning Mastery" property="og:site_name"/>
<meta content="https://www.facebook.com/Machine-Learning-Mastery-1429846323896563/" property="article:publisher"/>
<meta content="https://www.facebook.com/jason.brownlee.39" property="article:author"/>
<meta content="Deep Learning for Natural Language Processing" property="article:section"/>
<meta content="2017-12-31T18:00:52+00:00" property="article:published_time"/>
<meta content="2017-11-21T00:08:54+00:00" property="article:modified_time"/>
<meta content="2017-11-21T00:08:54+00:00" property="og:updated_time"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" property="og:image"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" property="og:image:secure_url"/>
<meta content="640" property="og:image:width"/>
<meta content="360" property="og:image:height"/>
<meta content="Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation" property="og:image:alt"/>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Organization","url":"https:\/\/machinelearningmastery.com\/","sameAs":["https:\/\/www.facebook.com\/Machine-Learning-Mastery-1429846323896563\/","https:\/\/www.linkedin.com\/in\/jasonbrownlee","https:\/\/plus.google.com\/u\/0\/b\/117073416089354242117\/+MachinelearningmasteryHome\/","https:\/\/twitter.com\/TeachTheMachine"],"@id":"https:\/\/machinelearningmastery.com\/#organization","name":"Machine Learning Mastery","logo":"https:\/\/machinelearningmastery.com\/wp-content\/uploads\/2016\/09\/cropped-icon.png"}</script>
<!-- / Yoast SEO plugin. -->
<link href="//s.w.org" rel="dns-prefetch"/>
<link href="https://feeds.feedburner.com/MachineLearningMastery" rel="alternate" title="Machine Learning Mastery » Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/comments/feed/" rel="alternate" title="Machine Learning Mastery » Comments Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/feed/" rel="alternate" title="Machine Learning Mastery » Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation Comments Feed" type="application/rss+xml"/>
<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/machinelearningmastery.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.8"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56760,9792,65039],[55358,56760,8203,9792,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<style media="all" type="text/css">
.wpautoterms-footer{background-color:#ffffff;text-align:center;}
.wpautoterms-footer a{color:#000000;font-family:Arial, sans-serif;font-size:14px;}
.wpautoterms-footer .separator{color:#cccccc;font-family:Arial, sans-serif;font-size:14px;}</style>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta" id="crayon-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/auto-terms-of-service-and-privacy-policy/css/wpautoterms.css?ver=4.9.8" id="wpautoterms_css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=5.0.5" id="contact-form-7-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/simple-social-buttons/assets/css/front.css?ver=2.0.20" id="ssb-front-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/ultimate-faqs/css/ewd-ufaq-styles.css?ver=4.9.8" id="ewd-ufaq-style-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/ultimate-faqs/css/rrssb-min.css?ver=4.9.8" id="ewd-ufaq-rrssb-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/integrations/testimonials/css/testimonials.css?ver=4.9.8" id="woo-testimonials-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/style.css?ver=5.9.21" id="theme-stylesheet-css" media="all" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/css/non-responsive.css" rel="stylesheet" type="text/css" />
<style type="text/css">.col-full, #wrapper { width: 960px; max-width: 960px; } #inner-wrapper { padding: 0; } body.full-width #header, #nav-container, body.full-width #content, body.full-width #footer-widgets, body.full-width #footer { padding-left: 0; padding-right: 0; } body.fixed-mobile #top, body.fixed-mobile #header-container, body.fixed-mobile #footer-container, body.fixed-mobile #nav-container, body.fixed-mobile #footer-widgets-container { min-width: 960px; padding: 0 1em; } body.full-width #content { width: auto; padding: 0 1em;}</style>
<![endif]-->
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery.js?ver=1.12.4" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/simple-social-buttons/assets/js/front.js?ver=2.0.20" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/third-party.min.js?ver=4.9.8" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/modernizr.min.js?ver=2.6.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/general.min.js?ver=4.9.8" type="text/javascript"></script>
<link href="https://machinelearningmastery.com/wp-json/" rel="https://api.w.org/"/>
<link href="https://machinelearningmastery.com/xmlrpc.php?rsd" rel="EditURI" title="RSD" type="application/rsd+xml"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/wlwmanifest.xml" rel="wlwmanifest" type="application/wlwmanifest+xml"/>
<link href="https://machinelearningmastery.com/?p=4531" rel="shortlink"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F" rel="alternate" type="application/json+oembed"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F&amp;format=xml" rel="alternate" type="text/xml+oembed"/>
<!-- Start Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44039733-3', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->
<style media="screen">

        .simplesocialbuttons.simplesocialbuttons_inline .ssb-fb-like {
      margin: ;
    }
         /*inline margin*/
    
  
  
  
  
  
          .simplesocialbuttons.simplesocialbuttons_inline.simplesocial-simple-icons button{
         margin: ;
     }

          /*margin-digbar*/

  
  
  
  
 
   
   

</style>
<script type="text/javascript">
        var ajaxurl = 'https://machinelearningmastery.com/wp-admin/admin-ajax.php';
    </script>
<!-- Custom CSS Styling -->
<style type="text/css">
#logo .site-title, #logo .site-description { display:none; }
body {background-repeat:no-repeat;background-position:top left;background-attachment:scroll;border-top:0px solid #000000;}
#header {background-repeat:no-repeat;background-position:left top;margin-top:0px;margin-bottom:0px;padding-top:10px;padding-bottom:10px;border:0px solid ;}
#logo .site-title a {font:bold 40px/1em "Helvetica Neue", Helvetica, sans-serif;color:#222222;}
#logo .site-description {font:normal 13px/1em "Helvetica Neue", Helvetica, sans-serif;color:#999999;}
body, p { font:normal 14px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
h1 { font:bold 28px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }h2 { font:bold 24px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }h3 { font:bold 20px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }h4 { font:bold 16px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }h5 { font:bold 14px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }h6 { font:bold 12px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#222222; }
.page-title, .post .title, .page .title {font:bold 28px/1.1em "Helvetica Neue", Helvetica, sans-serif;color:#222222;}
.post .title a:link, .post .title a:visited, .page .title a:link, .page .title a:visited {color:#222222}
.post-meta { font:normal 12px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
.entry, .entry p{ font:normal 15px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
.post-more {font:normal 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:;border-top:0px solid #e6e6e6;border-bottom:0px solid #e6e6e6;}
#post-author, #connect {border-top:1px solid #e6e6e6;border-bottom:1px solid #e6e6e6;border-left:1px solid #e6e6e6;border-right:1px solid #e6e6e6;border-radius:5px;-moz-border-radius:5px;-webkit-border-radius:5px;background-color:#fafafa}
.nav-entries a, .woo-pagination { font:normal 13px/1em "Helvetica Neue", Helvetica, sans-serif;color:#888; }
.woo-pagination a, .woo-pagination a:hover {color:#888!important}
.widget h3 {font:bold 14px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#555555;border-bottom:1px solid #e6e6e6;}
.widget_recent_comments li, #twitter li { border-color: #e6e6e6;}
.widget p, .widget .textwidget { font:normal 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
.widget {font:normal 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555;border-radius:0px;-moz-border-radius:0px;-webkit-border-radius:0px;}
#tabs .inside li a, .widget_woodojo_tabs .tabbable .tab-pane li a { font:bold 12px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
#tabs .inside li span.meta, .widget_woodojo_tabs .tabbable .tab-pane li span.meta { font:300 11px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
#tabs ul.wooTabs li a, .widget_woodojo_tabs .tabbable .nav-tabs li a { font:300 11px/2em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
@media only screen and (min-width:768px) {
ul.nav li a, #navigation ul.rss a, #navigation ul.cart a.cart-contents, #navigation .cart-contents #navigation ul.rss, #navigation ul.nav-search, #navigation ul.nav-search a { font:bold 18px/1.2em "Helvetica Neue", Helvetica, sans-serif;color:#4c89bf; } #navigation ul.rss li a:before, #navigation ul.nav-search a.search-contents:before { color:#4c89bf;}
#navigation ul.nav > li a:hover, #navigation ul.nav > li:hover a, #navigation ul.nav li ul li a, #navigation ul.cart > li:hover > a, #navigation ul.cart > li > ul > div, #navigation ul.cart > li > ul > div p, #navigation ul.cart > li > ul span, #navigation ul.cart .cart_list a, #navigation ul.nav li.current_page_item a, #navigation ul.nav li.current_page_parent a, #navigation ul.nav li.current-menu-ancestor a, #navigation ul.nav li.current-cat a, #navigation ul.nav li.current-menu-item a { color:#4c89bf!important; }
#navigation ul.nav > li a:hover, #navigation ul.nav > li:hover, #navigation ul.nav li ul, #navigation ul.cart li:hover a.cart-contents, #navigation ul.nav-search li:hover a.search-contents, #navigation ul.nav-search a.search-contents + ul, #navigation ul.cart a.cart-contents + ul, #navigation ul.nav li.current_page_item a, #navigation ul.nav li.current_page_parent a, #navigation ul.nav li.current-menu-ancestor a, #navigation ul.nav li.current-cat a, #navigation ul.nav li.current-menu-item a{background-color:#ffffff!important}
#navigation ul.nav li ul, #navigation ul.cart > li > ul > div  { border: 0px solid #dbdbdb; }
#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation ul.nav > li  { border-right: 0px solid #dbdbdb; }#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation { box-shadow: none; -moz-box-shadow: none; -webkit-box-shadow: none; }#navigation ul li:first-child, #navigation ul li:first-child a { border-radius:0px 0 0 0px; -moz-border-radius:0px 0 0 0px; -webkit-border-radius:0px 0 0 0px; }
#navigation {background:#ffffff;border-top:0px solid #dbdbdb;border-bottom:0px solid #dbdbdb;border-left:0px solid #dbdbdb;border-right:0px solid #dbdbdb;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
#top ul.nav li a { font:normal 12px/1.6em "Helvetica Neue", Helvetica, sans-serif;color:#ddd; }
}
#footer, #footer p { font:normal 13px/1.4em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
#footer {border-top:1px solid #dbdbdb;border-bottom:0px solid ;border-left:0px solid ;border-right:0px solid ;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
.magazine #loopedSlider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-magazine .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.magazine #loopedSlider .content .excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-magazine .slide-content p, .wooslider-theme-magazine .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.magazine .block .post .title a {font:bold 18px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
#loopedSlider.business-slider .content h2 { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#loopedSlider.business-slider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#wrapper #loopedSlider.business-slider .content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.archive_header { font:bold 18px/1em Arial, sans-serif;color:#222222; }
.archive_header {border-bottom:1px solid #e6e6e6;}
.archive_header .catrss { display:none; }
</style>
<!-- Woo Shortcodes CSS -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/functions/css/shortcodes.css" rel="stylesheet" type="text/css"/>
<!-- Custom Stylesheet -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/custom.css" rel="stylesheet" type="text/css"/>
<!-- Theme version -->
<meta content="Canvas 5.9.21" name="generator"/>
<meta content="WooFramework 6.2.9" name="generator"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-32x32.png" rel="icon" sizes="32x32"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-192x192.png" rel="icon" sizes="192x192"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-180x180.png" rel="apple-touch-icon-precomposed"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-270x270.png" name="msapplication-TileImage"/>
</head>
<body class="post-template-default single single-post postid-4531 single-format-standard chrome alt-style-default two-col-left width-960 two-col-left-960">
<div id="wrapper">
<div id="inner-wrapper">
<h3 class="nav-toggle icon"><a href="#navigation">Navigation</a></h3>
<header class="col-full" id="header">
<div id="logo">
<a href="https://machinelearningmastery.com/" title="Making developers awesome at machine learning"><img alt="Machine Learning Mastery" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/09/icon-100x100.png"/></a>
<span class="site-title"><a href="https://machinelearningmastery.com/">Machine Learning Mastery</a></span>
<span class="site-description">Making developers awesome at machine learning</span>
</div>
<div class="header-widget">
<div class="widget widget_text" id="text-44"> <div class="textwidget"><p>Want help with deep learning for text? <a href="https://machinelearningmastery.lpages.co/dlfnlp-mini-course/">Take the FREE Mini-Course</a></p>
</div>
</div><div class="widget widget_search" id="search-3"><div class="search_main">
<form action="https://machinelearningmastery.com/" class="searchform" method="get">
<input class="field s" name="s" onblur="if (this.value == '') {this.value = 'Search...';}" onfocus="if (this.value == 'Search...') {this.value = '';}" type="text" value="Search..."/>
<input name="post_type" type="hidden" value="post"/>
<button class="fa fa-search submit" name="submit" type="submit" value="Search"></button>
</form>
<div class="fix"></div>
</div></div> </div>
</header>
<nav class="col-full" id="navigation" role="navigation">
<section class="menus">
<a class="nav-home" href="https://machinelearningmastery.com"><span>Home</span></a>
<h3>Main Menu</h3><ul class="nav fl" id="main-nav"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-6503" id="menu-item-6503"><a href="https://machinelearningmastery.com/start-here/">Start Here</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-6501" id="menu-item-6501"><a href="https://machinelearningmastery.com/blog/">Blog</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-6506" id="menu-item-6506"><a href="#">Topics</a>
<ul class="sub-menu">
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6508" id="menu-item-6508"><a href="https://machinelearningmastery.com/category/deep-learning/">Deep Learning (Keras)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6511" id="menu-item-6511"><a href="https://machinelearningmastery.com/category/lstm/">LSTMs</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6509" id="menu-item-6509"><a href="https://machinelearningmastery.com/category/deep-learning-time-series/">Deep Learning for Time Series</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-6515" id="menu-item-6515"><a href="https://machinelearningmastery.com/category/natural-language-processing/">Deep Learning for NLP</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6512" id="menu-item-6512"><a href="https://machinelearningmastery.com/category/machine-learning-algorithms/">Understand Algorithms</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6507" id="menu-item-6507"><a href="https://machinelearningmastery.com/category/algorithms-from-scratch/">Code Algorithms (Python)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6513" id="menu-item-6513"><a href="https://machinelearningmastery.com/category/machine-learning-process/">Machine Learning Process</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6516" id="menu-item-6516"><a href="https://machinelearningmastery.com/category/python-machine-learning/">Python (scikit-learn)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6517" id="menu-item-6517"><a href="https://machinelearningmastery.com/category/r-machine-learning/">R (caret)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6522" id="menu-item-6522"><a href="https://machinelearningmastery.com/category/weka-machine-learning/">Weka (no code)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6518" id="menu-item-6518"><a href="https://machinelearningmastery.com/category/start-machine-learning/">Getting Started</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6510" id="menu-item-6510"><a href="https://machinelearningmastery.com/category/linear-algebra/">Linear Algebra</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6519" id="menu-item-6519"><a href="https://machinelearningmastery.com/category/statistical-methods/">Statistical Methods</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6520" id="menu-item-6520"><a href="https://machinelearningmastery.com/category/time-series/">Time Series (introductory)</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6523" id="menu-item-6523"><a href="https://machinelearningmastery.com/category/xgboost/">XGBoost</a></li>
<li class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-6514" id="menu-item-6514"><a href="https://machinelearningmastery.com/category/machine-learning-resources/">Resources</a></li>
</ul>
</li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-6502" id="menu-item-6502"><a href="https://machinelearningmastery.com/products/">Ebooks</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-6500" id="menu-item-6500"><a href="https://machinelearningmastery.com/faq/">FAQ</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-6504" id="menu-item-6504"><a href="https://machinelearningmastery.com/about/">About</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-6505" id="menu-item-6505"><a href="https://machinelearningmastery.com/contact/">Contact</a></li>
</ul> <div class="side-nav">
</div><!-- /#side-nav -->
</section><!-- /.menus -->
<a class="nav-close" href="#top"><span>Return to Content</span></a>
</nav>
<!-- #content Starts -->
<div class="col-full" id="content">
<div id="main-sidebar-container">
<!-- #main Starts -->
<section id="main">
<article class="post-4531 post type-post status-publish format-standard has-post-thumbnail hentry category-natural-language-processing">
<header>
<h1 class="title entry-title">Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</h1> </header>
<div class="post-meta"><span class="small">By</span> <span class="author vcard"><span class="fn"><a href="https://machinelearningmastery.com/author/jasonb/" rel="author" title="Posts by Jason Brownlee">Jason Brownlee</a></span></span> <span class="small">on</span> <abbr class="date time published updated" title="2018-01-01T05:00:52+1100">January 1, 2018</abbr> <span class="small">in</span> <span class="categories"><a href="https://machinelearningmastery.com/category/natural-language-processing/" title="View all items in Deep Learning for Natural Language Processing">Deep Learning for Natural Language Processing</a></span> </div>
<section class="entry">
<div class="simplesocialbuttons simplesocial-simple-icons simplesocialbuttons_inline simplesocialbuttons-align-left post-4531 post simplesocialbuttons-inline-no-animation">
<button class="ssb_tweet-icon" data-href="https://twitter.com/share?text=Encoder-Decoder+Recurrent+Neural+Network+Models+for+Neural+Machine+Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" rel="nofollow">
<span class="icon"><svg viewbox="0 0 72 72" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h72v72H0z" fill="none"></path><path class="icon" d="M68.812 15.14c-2.348 1.04-4.87 1.744-7.52 2.06 2.704-1.62 4.78-4.186 5.757-7.243-2.53 1.5-5.33 2.592-8.314 3.176C56.35 10.59 52.948 9 49.182 9c-7.23 0-13.092 5.86-13.092 13.093 0 1.026.118 2.02.338 2.98C25.543 24.527 15.9 19.318 9.44 11.396c-1.125 1.936-1.77 4.184-1.77 6.58 0 4.543 2.312 8.552 5.824 10.9-2.146-.07-4.165-.658-5.93-1.64-.002.056-.002.11-.002.163 0 6.345 4.513 11.638 10.504 12.84-1.1.298-2.256.457-3.45.457-.845 0-1.666-.078-2.464-.23 1.667 5.2 6.5 8.985 12.23 9.09-4.482 3.51-10.13 5.605-16.26 5.605-1.055 0-2.096-.06-3.122-.184 5.794 3.717 12.676 5.882 20.067 5.882 24.083 0 37.25-19.95 37.25-37.25 0-.565-.013-1.133-.038-1.693 2.558-1.847 4.778-4.15 6.532-6.774z" fill="#fff"></path></svg></span><i class="simplesocialtxt">Tweet </i></button>
<button class="ssb_fbshare-icon" data-href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" target="_blank">
<span class="icon"><svg class="_1pbq" color="#ffffff" viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path class="icon" d="M8 14H3.667C2.733 13.9 2 13.167 2 12.233V3.667A1.65 1.65 0 0 1 3.667 2h8.666A1.65 1.65 0 0 1 14 3.667v8.566c0 .934-.733 1.667-1.667 1.767H10v-3.967h1.3l.7-2.066h-2V6.933c0-.466.167-.9.867-.9H12v-1.8c.033 0-.933-.266-1.533-.266-1.267 0-2.434.7-2.467 2.133v1.867H6v2.066h2V14z" fill="#ffffff" fill-rule="evenodd"></path></svg></span>
<span class="simplesocialtxt">Share </span> </button>
<button class="ssb_linkedin-icon" data-href="https://www.linkedin.com/cws/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;">
<span class="icon"> <svg enable-background="new -301.4 387.5 15 14.1" height="14.1px" id="Layer_1" version="1.1" viewbox="-301.4 387.5 15 14.1" width="15px" x="0px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" y="0px"> <g id="XMLID_398_"> <path d="M-296.2,401.6c0-3.2,0-6.3,0-9.5h0.1c1,0,2,0,2.9,0c0.1,0,0.1,0,0.1,0.1c0,0.4,0,0.8,0,1.2 c0.1-0.1,0.2-0.3,0.3-0.4c0.5-0.7,1.2-1,2.1-1.1c0.8-0.1,1.5,0,2.2,0.3c0.7,0.4,1.2,0.8,1.5,1.4c0.4,0.8,0.6,1.7,0.6,2.5 c0,1.8,0,3.6,0,5.4v0.1c-1.1,0-2.1,0-3.2,0c0-0.1,0-0.1,0-0.2c0-1.6,0-3.2,0-4.8c0-0.4,0-0.8-0.2-1.2c-0.2-0.7-0.8-1-1.6-1 c-0.8,0.1-1.3,0.5-1.6,1.2c-0.1,0.2-0.1,0.5-0.1,0.8c0,1.7,0,3.4,0,5.1c0,0.2,0,0.2-0.2,0.2c-1,0-1.9,0-2.9,0 C-296.1,401.6-296.2,401.6-296.2,401.6z" fill="#FFFFFF" id="XMLID_399_"></path> <path d="M-298,401.6L-298,401.6c-1.1,0-2.1,0-3,0c-0.1,0-0.1,0-0.1-0.1c0-3.1,0-6.1,0-9.2 c0-0.1,0-0.1,0.1-0.1c1,0,2,0,2.9,0h0.1C-298,395.3-298,398.5-298,401.6z" fill="#FFFFFF" id="XMLID_400_"></path> <path d="M-299.6,390.9c-0.7-0.1-1.2-0.3-1.6-0.8c-0.5-0.8-0.2-2.1,1-2.4c0.6-0.2,1.2-0.1,1.8,0.2 c0.5,0.4,0.7,0.9,0.6,1.5c-0.1,0.7-0.5,1.1-1.1,1.3C-299.1,390.8-299.4,390.8-299.6,390.9L-299.6,390.9z" fill="#FFFFFF" id="XMLID_401_"></path> </g> </svg> </span>
<span class="simplesocialtxt">Share</span> </button>
<button class="ssb_gplus-icon" data-href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;">
<span class="icon"><svg class="ozWidgetRioButtonSvg_ ozWidgetRioButtonPlusOne_" height="18px" preserveaspectratio="xMidYMid meet" version="1.1" viewbox="-10 -6 60 36" width="30px" xmlns="http://www.w3.org/2000/svg"><path d="M30 7h-3v4h-4v3h4v4h3v-4h4v-3h-4V7z"></path><path d="M11 9.9v4h5.4C16 16.3 14 18 11 18c-3.3 0-5.9-2.8-5.9-6S7.7 6 11 6c1.5 0 2.8.5 3.8 1.5l2.9-2.9C15.9 3 13.7 2 11 2 5.5 2 1 6.5 1 12s4.5 10 10 10c5.8 0 9.6-4.1 9.6-9.8 0-.7-.1-1.5-.2-2.2H11z"></path></svg></span>
<span class="simplesocialtxt">Google Plus </span></button>
</div>
<p>The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods.</p>
<p>This architecture is very new, having only been pioneered in 2014, although, has been adopted as the core technology inside <a href="https://translate.google.com/">Google’s translate service</a>.</p>
<p>In this post, you will discover the two seminal examples of the encoder-decoder model for neural machine translation.</p>
<p>After reading this post, you will know:</p>
<ul>
<li>The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.</li>
<li>The so-called “<em>Sutskever model</em>” for direct end-to-end machine translation.</li>
<li>The so-called “<em>Cho model</em>” that extends the architecture with GRU units and an attention mechanism.</li>
</ul>
<p>Let’s get started.</p>
<div class="wp-caption aligncenter" id="attachment_4535" style="width: 650px"><img alt="Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation" class="size-full wp-image-4535" height="360" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation-300x169.jpg 300w" width="640"/><p class="wp-caption-text">Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation<br/>Photo by <a href="https://www.flickr.com/photos/fabiuxfabiux/34223907581/">Fabio Pani</a>, some rights reserved.</p></div>
<h2>Encoder-Decoder Architecture for NMT</h2>
<p>The Encoder-Decoder architecture with recurrent neural networks has become an effective and standard approach for both neural machine translation (NMT) and sequence-to-sequence (seq2seq) prediction in general.</p>
<p>The key benefits of the approach are the ability to train a single end-to-end model directly on source and target sentences and the ability to handle variable length input and output sequences of text.</p>
<p>As evidence of the success of the method, the architecture is the core of the <a href="https://translate.google.com/">Google translation service</a>.</p>
<blockquote><p>Our model follows the common sequence-to-sequence learning framework with attention. It has three components: an encoder network, a decoder network, and an attention network.</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1609.08144">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a>, 2016</p>
<p>In this post, we will take a closer look at two different research projects that developed the same Encoder-Decoder architecture at the same time in 2014 and achieved results that put the spotlight on the approach. They are:</p>
<ul>
<li>Sutskever NMT Model</li>
<li>Cho NMT Model</li>
</ul>
<p>For more on the architecture, see the post:</p>
<ul>
<li><a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/">Encoder-Decoder Long Short-Term Memory Networks</a></li>
</ul>
<p></p><div class="woo-sc-hr"></div>
<center>
<h3>Need help with Deep Learning for Text Data?</h3>
<p>Take my free 7-day email crash course now (with code).</p>
<p>Click to sign-up and also get a free PDF Ebook version of the course.</p>
<p><a href="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" rel="noopener" style="background: #ffce0a; color: #ffffff; text-decoration: none; font-family: Helvetica, Arial, sans-serif; font-weight: bold; font-size: 16px; line-height: 20px; padding: 10px; display: inline-block; max-width: 300px; border-radius: 5px; text-shadow: rgba(0, 0, 0, 0.25) 0px -1px 1px; box-shadow: rgba(255, 255, 255, 0.5) 0px 1px 3px inset, rgba(0, 0, 0, 0.5) 0px 1px 3px;" target="_blank">Start Your FREE Crash-Course Now</a><script data-config="%7B%7D" data-leadbox="144855173f72a2:164f8be4f346dc" data-url="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" src="https://machinelearningmastery.lpages.co/leadbox-1509466860.js" type="text/javascript"></script></p>
</center>
<p></p><div class="woo-sc-hr"></div>
<h2>Sutskever NMT Model</h2>
<p>In this section, we will look at the neural machine translation model developed by <a href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever</a>, et al. as described in their 2014 paper “<a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>“. We will refer to it as the “<em>Sutskever NMT Model</em>“, for lack of a better name.</p>
<p>This is an important paper as it was one of the first to introduce the Encoder-Decoder model for machine translation and more generally sequence-to-sequence learning.</p>
<p>It is an important model in the field of machine translation as it was one of the first neural machine translation systems to outperform a baseline statistical machine learning model on a large translation task.</p>
<h3>Problem</h3>
<p>The model was applied to English to French translation, specifically the <a href="http://www.statmt.org/wmt14/translation-task.html">WMT 2014 translation task</a>.</p>
<p>The translation task was processed one sentence at a time, and an end-of-sequence (&lt;EOS&gt;) token was added to the end of output sequences during training to signify the end of the translated sequence. This allowed the model to be capable of predicting variable length output sequences.</p>
<blockquote><p>Note that we require that each sentence ends with a special end-of-sentence symbol “&lt;EOS&gt;”, which enables the model to define a distribution over sequences of all possible lengths.</p></blockquote>
<p>The model was trained on a subset of the 12 Million sentences in the dataset, comprised of 348 Million French words and 304 Million English words. This set was chosen because it was pre-tokenized.</p>
<p>The source vocabulary was reduced to the 160,000 most frequent source English words and 80,000 of the most frequent target French words. All out-of-vocabulary words were replaced with the “UNK” token.</p>
<h3>Model</h3>
<p>An Encoder-Decoder architecture was developed where an input sequence was read in entirety and encoded to a fixed-length internal representation.</p>
<p>A decoder network then used this internal representation to output words until the end of sequence token was reached. LSTM networks were used for both the encoder and decoder.</p>
<blockquote><p>The idea is to use one LSTM to read the input sequence, one timestep at a time, to obtain large fixed-dimensional vector representation, and then to use another LSTM to extract the output sequence from that vector</p></blockquote>
<p>The final model was an ensemble of 5 deep learning models. A left-to-right beam search was used during the inference of the translations.</p>
<div class="wp-caption aligncenter" id="attachment_4532" style="width: 1590px"><img alt="Depiction of Sutskever Encoder-Decoder Model for Text Translation" class="size-full wp-image-4532" height="356" sizes="(max-width: 1580px) 100vw, 1580px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation.png 1580w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-300x68.png 300w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-768x173.png 768w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-1024x231.png 1024w" width="1580"/><p class="wp-caption-text">Depiction of Sutskever Encoder-Decoder Model for Text Translation<br/>Taken from “Sequence to Sequence Learning with Neural Networks,” 2014.</p></div>
<h3>Model Configuration</h3>
<ul>
<li>Input sequences were reversed.</li>
<li>A 1000-dimensional word embedding layer was used to represent the input words.</li>
<li>Softmax was used on the output layer.</li>
<li>The input and output models had 4 layers with 1,000 units per layer.</li>
<li>The model was fit for 7.5 epochs where some learning rate decay was performed.</li>
<li>A batch-size of 128 sequences was used during training.</li>
<li>Gradient clipping was used during training to mitigate the chance of gradient explosions.</li>
<li>Batches were comprised of sentences with roughly the same length to speed-up computation.</li>
</ul>
<p>The model was fit on an 8-GPU machine where each layer was run on a different GPU. Training took 10 days.</p>
<blockquote><p>The resulting implementation achieved a speed of 6,300 (both English and French) words per second with a minibatch size of 128. Training took about ten days with this implementation.</p></blockquote>
<h3>Result</h3>
<p>The system achieved a BLEU score of 34.81, which is a good score compared to the baseline score developed with a statistical machine translation system of 33.30. Importantly, this is the first example of a neural machine translation system that outperformed a phrase-based statistical machine translation baseline on a large scale problem.</p>
<blockquote><p>… we obtained a BLEU score of 34.81 […] This is by far the best result achieved by direct translation with large neural networks. For comparison, the BLEU score of an SMT baseline on this dataset is 33.30</p></blockquote>
<p>The final model was used t ore-score the list of <a href="http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/">best translations</a> and improved the score to 36.5 which brings it close to the best result at the time of 37.0.</p>
<p>You can see a video of the talk associated with the paper <a href="https://www.youtube.com/watch?v=-uyXE7dY5H0">here</a>:</p>
<p><iframe allowfullscreen="" frameborder="0" gesture="media" height="281" src="https://www.youtube.com/embed/-uyXE7dY5H0?feature=oembed" width="500"></iframe></p>
<h2>Cho NMT Model</h2>
<p>In this section, we will look at the neural machine translation system described by <a href="http://www.kyunghyuncho.me/">Kyunghyun Cho</a>, et al. in their 2014 paper titled “<a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a>.” We will refer to it as the “<em>Cho NMT Model</em>” model for lack of a better name.</p>
<p>Importantly, the Cho Model is used only to score candidate translations and is not used directly for translation like the Sutskever model above. Although extensions to the work to better diagnose and improve the model do use it directly and alone for translation.</p>
<h3>Problem</h3>
<p>As above, the problem is the English to French translation task from the WMT 2014 workshop.</p>
<p>The source and target vocabulary were limited to the most frequent 15,000 French and English words which covers 93% of the dataset, and out of vocabulary words were replaced with “UNK”.</p>
<h3>Model</h3>
<p>The model uses the same two-model approach, here giving it the explicit name of the encoder-decoder architecture.</p>
<blockquote><p>… called RNN Encoder–Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols.</p></blockquote>
<div class="wp-caption aligncenter" id="attachment_4533" style="width: 650px"><img alt="Depiction of the Encoder-Decoder architecture" class="size-full wp-image-4533" height="654" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture.png 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture-294x300.png 294w" width="640"/><p class="wp-caption-text">Depiction of the Encoder-Decoder architecture.<br/>Taken from “Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.”</p></div>
<p>The implementation does not use LSTM units; instead, a simpler recurrent neural network unit is developed called the gated recurrent unit or GRU.</p>
<blockquote><p>… we also propose a new type of hidden unit that has been motivated by the LSTM unit but is much simpler to compute and implement.</p></blockquote>
<h3>Model Configuration</h3>
<ul>
<li>A 100-dimensional word embedding was used to represent the input words.</li>
<li>The encoder and decoder were configured with 1 layer of 1000 GRU units.</li>
<li>500 Maxout units pooling 2 inputs were used after the decoder.</li>
<li>A batch size of 64 sentences was used during training.</li>
</ul>
<p>The model was trained for approximately 2 days.</p>
<h3>Extensions</h3>
<p>In the paper “<a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>,” Cho, et al. investigate the limitations of their model. They discover that performance degrades quickly with the increase in the length of input sentences and with the number of words outside of the vocabulary.</p>
<blockquote><p>Our analysis revealed that the performance of the neural machine translation suffers significantly from the length of sentences.</p></blockquote>
<p>They provide a useful graph of the performance of the model as the length of the sentence is increased that captures the graceful loss in skill with increased difficulty.</p>
<div class="wp-caption aligncenter" id="attachment_4534" style="width: 496px"><img alt="Loss in model skill with increased sentence length" class="size-full wp-image-4534" height="346" sizes="(max-width: 486px) 100vw, 486px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length.png 486w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length-300x214.png 300w" width="486"/><p class="wp-caption-text">Loss in model skill with increased sentence length.<br/>Taken from “On the Properties of Neural Machine Translation: Encoder-Decoder Approaches.”</p></div>
<p>To address the problem of unknown words, they suggest dramatically increasing the vocabulary of known words during training.</p>
<p>They address the problem of sentence length in a follow-up paper titled “<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>” in which they propose the use of an attention mechanism. Instead of encoding the input sentence to a fixed length vector, a fuller representation of the encoded input is kept and the model learns to use to pay attention to different parts of the input for each word output by the decoder.</p>
<blockquote><p>Each time the proposed model generates a word in a translation, it (soft-)searches for a set of positions in a source sentence where the most relevant information is concentrated. The model then predicts a target word based on the context vectors associated with these source positions and all the previous generated target words.</p></blockquote>
<p>A wealth of technical details are provided in the paper; for example:</p>
<ul>
<li>A similarly configured model is used, although with bidirectional layers.</li>
<li>The data is prepared such that 30,000 of the most common words are kept in the vocabulary.</li>
<li>The model is first trained with sentences with a length up to 20 words, then with sentences with a length up to 50 words.</li>
<li>A batch size of 80 sentences is used and the model was fit for 4-6 epochs.</li>
<li>A beam search was used during the inference to find the most likely sequence of words for each translation.</li>
</ul>
<p>This time the model takes approximately 5 days to train. The code for this follow-up work is also <a href="https://github.com/lisa-groundhog/GroundHog">made available</a>.</p>
<p>As with the Sutskever, the model achieved results within the reach of classical phrase-based statistical approaches.</p>
<blockquote><p>Perhaps more importantly, the proposed approach achieved a translation performance comparable to the existing phrase-based statistical machine translation. It is a striking result, considering that the proposed architecture, or the whole family of neural machine translation, has only been proposed as recently as this year. We believe the architecture proposed here is a promising step toward better machine translation and a better understanding of natural languages in general.</p></blockquote>
<p>Kyunghyun Cho is also the author of a 2015 series of posts on the Nvidia developer blog on the topic of the encoder-decoder architecture for neural machine translation titled “<em>Introduction to Neural Machine Translation with GPUs.</em>” The series provides a good introduction to the topic and the model; see <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/">part 1</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/">part 2</a>, and <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">part 3</a>.</p>
<h2>Further Reading</h2>
<p>This section provides more resources on the topic if you are looking to go deeper.</p>
<ul>
<li><a href="https://arxiv.org/abs/1609.08144">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a>, 2016.</li>
<li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>, 2014.</li>
<li><a href="https://www.youtube.com/watch?v=-uyXE7dY5H0">Presentation for Sequence to Sequence Learning with Neural Networks</a>, 2016.</li>
<li><a href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever Homepage</a></li>
<li><a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>, 2014.</li>
<li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>, 2014.</li>
<li><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>, 2014.</li>
<li><a href="http://www.kyunghyuncho.me/">Kyunghyun Cho Homepage</a></li>
<li>Introduction to Neural Machine Translation with GPUs (<a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/">part1</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/">part2</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">part3</a>), 2015.</li>
</ul>
<h2>Summary</h2>
<p>In this post, you discovered two examples of the encoder-decoder model for neural machine translation.</p>
<p>Specifically, you learned:</p>
<ul>
<li>The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.</li>
<li>The so-called “Sutskever model” for direct end-to-end machine translation.</li>
<li>The so-called “Cho model” that extends the architecture with GRU units and an attention mechanism.</li>
</ul>
<p>Do you have any questions?<br/>
Ask your questions in the comments below and I will do my best to answer.</p>
<div class="awac-wrapper"><div class="awac widget text-42"> <div class="textwidget"><p></p><center><br/>
<div class="woo-sc-hr"></div>
<h2>Develop Deep Learning models for Text Data Today!</h2>
<p><a href="/deep-learning-for-nlp/"><img align="left" alt="Deep Learning for Natural Language Processing" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png" style="border: 0;"/></a></p>
<h4>Develop Your Own Text models in Minutes</h4>
<p>…with just a few lines of python code</p>
<p>Discover how in my new Ebook:<br/>
<a href="/deep-learning-for-nlp/">Deep Learning for Natural Language Processing</a></p>
<p>It provides <strong>self-study tutorials</strong> on topics like:<br/>
<em>Bag-of-Words, Word Embedding, Language Models, Caption Generation, Text Translation</em> and much more…</p>
<h4>Finally Bring Deep Learning to your Natural Language Processing Projects</h4>
<p>Skip the Academics. Just Results.</p>
<p><a href="/deep-learning-for-nlp/">Click to learn more</a>.<br/>
</p><div class="woo-sc-hr"></div><br/>
</center>
</div>
</div></div><div class="simplesocialbuttons simplesocial-simple-icons simplesocialbuttons_inline simplesocialbuttons-align-left post-4531 post simplesocialbuttons-inline-no-animation">
<button class="ssb_tweet-icon" data-href="https://twitter.com/share?text=Encoder-Decoder+Recurrent+Neural+Network+Models+for+Neural+Machine+Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" rel="nofollow">
<span class="icon"><svg viewbox="0 0 72 72" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h72v72H0z" fill="none"></path><path class="icon" d="M68.812 15.14c-2.348 1.04-4.87 1.744-7.52 2.06 2.704-1.62 4.78-4.186 5.757-7.243-2.53 1.5-5.33 2.592-8.314 3.176C56.35 10.59 52.948 9 49.182 9c-7.23 0-13.092 5.86-13.092 13.093 0 1.026.118 2.02.338 2.98C25.543 24.527 15.9 19.318 9.44 11.396c-1.125 1.936-1.77 4.184-1.77 6.58 0 4.543 2.312 8.552 5.824 10.9-2.146-.07-4.165-.658-5.93-1.64-.002.056-.002.11-.002.163 0 6.345 4.513 11.638 10.504 12.84-1.1.298-2.256.457-3.45.457-.845 0-1.666-.078-2.464-.23 1.667 5.2 6.5 8.985 12.23 9.09-4.482 3.51-10.13 5.605-16.26 5.605-1.055 0-2.096-.06-3.122-.184 5.794 3.717 12.676 5.882 20.067 5.882 24.083 0 37.25-19.95 37.25-37.25 0-.565-.013-1.133-.038-1.693 2.558-1.847 4.778-4.15 6.532-6.774z" fill="#fff"></path></svg></span><i class="simplesocialtxt">Tweet </i></button>
<button class="ssb_fbshare-icon" data-href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" target="_blank">
<span class="icon"><svg class="_1pbq" color="#ffffff" viewbox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path class="icon" d="M8 14H3.667C2.733 13.9 2 13.167 2 12.233V3.667A1.65 1.65 0 0 1 3.667 2h8.666A1.65 1.65 0 0 1 14 3.667v8.566c0 .934-.733 1.667-1.667 1.767H10v-3.967h1.3l.7-2.066h-2V6.933c0-.466.167-.9.867-.9H12v-1.8c.033 0-.933-.266-1.533-.266-1.267 0-2.434.7-2.467 2.133v1.867H6v2.066h2V14z" fill="#ffffff" fill-rule="evenodd"></path></svg></span>
<span class="simplesocialtxt">Share </span> </button>
<button class="ssb_linkedin-icon" data-href="https://www.linkedin.com/cws/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;">
<span class="icon"> <svg enable-background="new -301.4 387.5 15 14.1" height="14.1px" id="Layer_1" version="1.1" viewbox="-301.4 387.5 15 14.1" width="15px" x="0px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" y="0px"> <g id="XMLID_398_"> <path d="M-296.2,401.6c0-3.2,0-6.3,0-9.5h0.1c1,0,2,0,2.9,0c0.1,0,0.1,0,0.1,0.1c0,0.4,0,0.8,0,1.2 c0.1-0.1,0.2-0.3,0.3-0.4c0.5-0.7,1.2-1,2.1-1.1c0.8-0.1,1.5,0,2.2,0.3c0.7,0.4,1.2,0.8,1.5,1.4c0.4,0.8,0.6,1.7,0.6,2.5 c0,1.8,0,3.6,0,5.4v0.1c-1.1,0-2.1,0-3.2,0c0-0.1,0-0.1,0-0.2c0-1.6,0-3.2,0-4.8c0-0.4,0-0.8-0.2-1.2c-0.2-0.7-0.8-1-1.6-1 c-0.8,0.1-1.3,0.5-1.6,1.2c-0.1,0.2-0.1,0.5-0.1,0.8c0,1.7,0,3.4,0,5.1c0,0.2,0,0.2-0.2,0.2c-1,0-1.9,0-2.9,0 C-296.1,401.6-296.2,401.6-296.2,401.6z" fill="#FFFFFF" id="XMLID_399_"></path> <path d="M-298,401.6L-298,401.6c-1.1,0-2.1,0-3,0c-0.1,0-0.1,0-0.1-0.1c0-3.1,0-6.1,0-9.2 c0-0.1,0-0.1,0.1-0.1c1,0,2,0,2.9,0h0.1C-298,395.3-298,398.5-298,401.6z" fill="#FFFFFF" id="XMLID_400_"></path> <path d="M-299.6,390.9c-0.7-0.1-1.2-0.3-1.6-0.8c-0.5-0.8-0.2-2.1,1-2.4c0.6-0.2,1.2-0.1,1.8,0.2 c0.5,0.4,0.7,0.9,0.6,1.5c-0.1,0.7-0.5,1.1-1.1,1.3C-299.1,390.8-299.4,390.8-299.6,390.9L-299.6,390.9z" fill="#FFFFFF" id="XMLID_401_"></path> </g> </svg> </span>
<span class="simplesocialtxt">Share</span> </button>
<button class="ssb_gplus-icon" data-href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="javascript:window.open(this.dataset.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;">
<span class="icon"><svg class="ozWidgetRioButtonSvg_ ozWidgetRioButtonPlusOne_" height="18px" preserveaspectratio="xMidYMid meet" version="1.1" viewbox="-10 -6 60 36" width="30px" xmlns="http://www.w3.org/2000/svg"><path d="M30 7h-3v4h-4v3h4v4h3v-4h4v-3h-4V7z"></path><path d="M11 9.9v4h5.4C16 16.3 14 18 11 18c-3.3 0-5.9-2.8-5.9-6S7.7 6 11 6c1.5 0 2.8.5 3.8 1.5l2.9-2.9C15.9 3 13.7 2 11 2 5.5 2 1 6.5 1 12s4.5 10 10 10c5.8 0 9.6-4.1 9.6-9.8 0-.7-.1-1.5-.2-2.2H11z"></path></svg></span>
<span class="simplesocialtxt">Google Plus </span></button>
</div>
</section><!-- /.entry -->
<div class="fix"></div>
<aside id="post-author">
<div class="profile-image"><img alt="" class="avatar avatar-80 photo" height="80" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=160&amp;d=mm&amp;r=g 2x" width="80"/></div>
<div class="profile-content">
<h4>About Jason Brownlee</h4>
		Jason Brownlee, PhD is a machine learning specialist who teaches developers how to get results with modern machine learning methods via hands-on tutorials.				<div class="profile-link">
<a href="https://machinelearningmastery.com/author/jasonb/">
				View all posts by Jason Brownlee <span class="meta-nav">→</span> </a>
</div><!--#profile-link-->
</div>
<div class="fix"></div>
</aside>
<div class="post-utility"></div>
</article><!-- /.post -->
<div class="post-entries">
<div class="nav-prev fl"><a href="https://machinelearningmastery.com/introduction-neural-machine-translation/" rel="prev"><i class="fa fa-angle-left"></i> A Gentle Introduction to Neural Machine Translation</a></div>
<div class="nav-next fr"><a href="https://machinelearningmastery.com/configure-encoder-decoder-model-neural-machine-translation/" rel="next">How to Configure an Encoder-Decoder Model for Neural Machine Translation <i class="fa fa-angle-right"></i></a></div>
<div class="fix"></div>
</div>
<div id="comments"> <h3 id="comments-title">12 Responses to <em>Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</em></h3>
<ol class="commentlist">
<li class="comment even thread-even depth-1" id="comment-425707">
<div class="comment-container" id="li-comment-425707">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/bcae215578dd8bcced346e7010d68b60?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bcae215578dd8bcced346e7010d68b60?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">vineet</span>
<span class="date">January 5, 2018 at 1:18 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425707" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>The post was inspiring! Thank you  jason.</p>
<div class="reply">
<a aria-label="Reply to vineet" class="comment-reply-link" href="#comment-425707" onclick='return addComment.moveForm( "comment-425707", "425707", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-425747">
<div class="comment-container" id="li-comment-425747">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 6, 2018 at 5:51 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425747" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks, I’m glad to hear that.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-425747" onclick='return addComment.moveForm( "comment-425747", "425747", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-425818">
<div class="comment-container" id="li-comment-425818">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/189ab65cabe6527b354b14e855473c27?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/189ab65cabe6527b354b14e855473c27?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Roa</span>
<span class="date">January 7, 2018 at 9:45 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425818" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>It’s an exciting, perfect.</p>
<div class="reply">
<a aria-label="Reply to Roa" class="comment-reply-link" href="#comment-425818" onclick='return addComment.moveForm( "comment-425818", "425818", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-425846">
<div class="comment-container" id="li-comment-425846">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 8, 2018 at 5:39 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425846" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-425846" onclick='return addComment.moveForm( "comment-425846", "425846", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-425992">
<div class="comment-container" id="li-comment-425992">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/ce623be2f3ffcc799bec04740be2856c?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/ce623be2f3ffcc799bec04740be2856c?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">BA</span>
<span class="date">January 9, 2018 at 9:08 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425992" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Can this technique be used for transliteration (of proper names)? Or would transliteration be simpler? If so, what is a good sequence-to-sequence model for transliteration English to a Arabic and Visa-versa</p>
<div class="reply">
<a aria-label="Reply to BA" class="comment-reply-link" href="#comment-425992" onclick='return addComment.moveForm( "comment-425992", "425992", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-426059">
<div class="comment-container" id="li-comment-426059">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 10, 2018 at 5:25 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-426059" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>I believe so.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-426059" onclick='return addComment.moveForm( "comment-426059", "426059", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-435608">
<div class="comment-container" id="li-comment-435608">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/3722115512acf6b2d757be50264bdc57?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/3722115512acf6b2d757be50264bdc57?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Gurpreet Josan</span>
<span class="date">April 22, 2018 at 2:35 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-435608" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Hi Jason,</p>
<p>I am learning a lot from your wonderful series of posts. Thanks for providing all this knowledge. I have a small query. I tried LSTM and GRU on transliteration task. The BLEU score of GRU came out to be 0.08 where as that of LSTM is 0.72. Why there is a huge difference? GRU is supposed to be working at par with LSTM. Any insight or pointer in this direction?</p>
<div class="reply">
<a aria-label="Reply to Gurpreet Josan" class="comment-reply-link" href="#comment-435608" onclick='return addComment.moveForm( "comment-435608", "435608", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-435623">
<div class="comment-container" id="li-comment-435623">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">April 22, 2018 at 6:02 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-435623" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>They are different, therefore cannot work on par.</p>
<p>Expect different results from different algorithms across problems.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-435623" onclick='return addComment.moveForm( "comment-435623", "435623", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-444185">
<div class="comment-container" id="li-comment-444185">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/2c1aed7ae96b67659cf39114f14d0cc0?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/2c1aed7ae96b67659cf39114f14d0cc0?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Atilla</span>
<span class="date">July 23, 2018 at 6:32 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-444185" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Can we use Bidirectional LSTM as a decoder in the encoder-decoder structure?</p>
<div class="reply">
<a aria-label="Reply to Atilla" class="comment-reply-link" href="#comment-444185" onclick='return addComment.moveForm( "comment-444185", "444185", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-444186">
<div class="comment-container" id="li-comment-444186">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">July 23, 2018 at 8:00 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-444186" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Sure.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-444186" onclick='return addComment.moveForm( "comment-444186", "444186", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-446852">
<div class="comment-container" id="li-comment-446852">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/70f5906861d4c4d9c7caaf10c969608b?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/70f5906861d4c4d9c7caaf10c969608b?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Joey Gao</span>
<span class="date">August 24, 2018 at 12:26 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-446852" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Hello Jason, I have 2 questions:<br/>
How long does seq2seq can process, 10? 100? or as many as 1000?<br/>
Can I use the seq2seq as a feature extractor just use the output of encoder as output feature when I feed the encoder and decoder same sequence?</p>
<div class="reply">
<a aria-label="Reply to Joey Gao" class="comment-reply-link" href="#comment-446852" onclick='return addComment.moveForm( "comment-446852", "446852", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-446857">
<div class="comment-container" id="li-comment-446857">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">August 24, 2018 at 2:10 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-446857" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Good question, perhaps 200-400 time steps in and out. maybe experiment to see what works.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="#comment-446857" onclick='return addComment.moveForm( "comment-446857", "446857", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ol>
</div> <div class="comment-respond" id="respond">
<h3 class="comment-reply-title" id="reply-title">Leave a Reply <small><a href="/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;">Click here to cancel reply.</a></small></h3> <form action="https://machinelearningmastery.com/wp-comments-post.php?wpe-comment-post=mlmastery" class="comment-form" id="commentform" method="post">
<p class="comment-form-comment"><label class="hide" for="comment">Comment</label> <textarea cols="50" id="comment" maxlength="65525" name="comment" required="required" rows="10" tabindex="4"></textarea></p><p class="comment-form-author"><input aria-required="true" class="txt" id="author" name="author" size="30" tabindex="1" type="text" value=""/><label for="author">Name <span class="required">(required)</span></label> </p>
<p class="comment-form-email"><input aria-required="true" class="txt" id="email" name="email" size="30" tabindex="2" type="text" value=""/><label for="email">Email (will not be published) <span class="required">(required)</span></label> </p>
<p class="comment-form-url"><input class="txt" id="url" name="url" size="30" tabindex="3" type="text" value=""/><label for="url">Website</label></p>
<p class="form-submit"><input class="submit" id="submit" name="submit" type="submit" value="Submit Comment"/> <input id="comment_post_ID" name="comment_post_ID" type="hidden" value="4531"/>
<input id="comment_parent" name="comment_parent" type="hidden" value="0"/>
</p><p style="display: none;"><input id="akismet_comment_nonce" name="akismet_comment_nonce" type="hidden" value="4bad2ef60a"/></p><p style="display: none;"><input id="ak_js" name="ak_js" type="hidden" value="223"/></p> </form>
</div><!-- #respond -->
</section><!-- /#main -->
<aside id="sidebar">
<div class="widget widget_woo_blogauthorinfo" id="woo_blogauthorinfo-2"><h3>Welcome to Machine Learning Mastery!</h3><span class="left"><img alt="" class="avatar avatar-100 photo" height="100" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=200&amp;d=mm&amp;r=g 2x" width="100"/></span>
<p>Hi, I'm Jason Brownlee, PhD
<br/>
I write tutorials to help developers (<i>like you</i>) get results with machine learning.</p>
<p><a href="/about">Read More</a></p>
<div class="fix"></div>
</div><div class="widget widget_text" id="text-43"> <div class="textwidget"><p></p><center><br/>
<strong>Deep Learning for NLP</strong><br/>
Develop deep learning models for text data.
<p><a href="/deep-learning-for-nlp/">Click to Get Started Now!</a><br/>
<a href="/deep-learning-for-nlp/"><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png"/></a><br/>
</p></center>
</div>
</div>
<div class="widget widget_woo_tabs" id="woo_tabs-2"> <div id="tabs">
<ul class="wooTabs">
<li class="popular"><a href="#tab-pop">Popular</a></li> </ul>
<div class="clear"></div>
<div class="boxes box inside">
<ul class="list" id="tab-pop">
<li>
<a href="https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/" title="How to Develop a Neural Machine Translation System from Scratch"><img alt="How to Develop a Neural Machine Translation System in Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/How-to-Develop-a-Neural-Machine-Translation-System-in-Keras-150x150.jpg" title="How to Develop a Neural Machine Translation System from Scratch" width="45"/></a> <a href="https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/" title="How to Develop a Neural Machine Translation System from Scratch">How to Develop a Neural Machine Translation System from Scratch</a>
<span class="meta">January 10, 2018</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" title="Difference Between Classification and Regression in Machine Learning"><img alt="Difference Between Classification and Regression in Machine Learning" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Difference-Between-Classification-and-Regression-in-Machine-Learning-150x150.jpg" title="Difference Between Classification and Regression in Machine Learning" width="45"/></a> <a href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" title="Difference Between Classification and Regression in Machine Learning">Difference Between Classification and Regression in Machine Learning</a>
<span class="meta">December 11, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/working-machine-learning-problem/" title="So, You are Working on a Machine Learning Problem..."><img alt="So, You are Working on a Machine Learning Problem..." class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/So-You-are-Working-on-a-Machine-Learning-Problem...-150x150.jpg" title="So, You are Working on a Machine Learning Problem..." width="45"/></a> <a href="https://machinelearningmastery.com/working-machine-learning-problem/" title="So, You are Working on a Machine Learning Problem…">So, You are Working on a Machine Learning Problem…</a>
<span class="meta">April 4, 2018</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/" title="How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis"><img alt="Plot of the Multichannel Convolutional Neural Network For Text" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Plot-of-the-Multichannel-Convolutional-Neural-Network-For-Text-150x150.png" title="How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis" width="45"/></a> <a href="https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/" title="How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis">How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis</a>
<span class="meta">January 12, 2018</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/" title="How to Make Predictions with Keras"><img alt="How to Make Classification and Regression Predictions for Deep Learning Models in Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/How-to-Make-Classification-and-Regression-Predictions-for-Deep-Learning-Models-in-Keras-150x150.jpg" title="How to Make Predictions with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/" title="How to Make Predictions with Keras">How to Make Predictions with Keras</a>
<span class="meta">April 9, 2018</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/" title="11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)"><img alt="11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/11-Classical-Time-Series-Forecasting-Methods-in-Python-Cheat-Sheet-150x150.jpg" title="11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/" title="11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)">11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)</a>
<span class="meta">August 6, 2018</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/" title="How to Visualize a Deep Learning Neural Network Model in Keras"><img alt="How to Visualize a Deep Learning Neural Network Model in Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/How-to-Visualize-a-Deep-Learning-Neural-Network-Model-in-Keras-150x150.jpg" title="How to Visualize a Deep Learning Neural Network Model in Keras" width="45"/></a> <a href="https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/" title="How to Visualize a Deep Learning Neural Network Model in Keras">How to Visualize a Deep Learning Neural Network Model in Keras</a>
<span class="meta">December 13, 2017</span>
<div class="fix"></div>
</li>
</ul>
</div><!-- /.boxes -->
</div><!-- /wooTabs -->
</div> <div class="widget_text widget widget_custom_html" id="custom_html-2"><h3>You might also like…</h3><div class="textwidget custom-html-widget"><ul>
<li><a href="/setup-python-environment-machine-learning-deep-learning-anaconda/">How to Install Python for Machine Learning</a></li>
<li><a href="/machine-learning-in-python-step-by-step/">Your First Machine Learning Project in Python</a></li>
<li><a href="/tutorial-first-neural-network-python-keras/">Your First Neural Network in Python</a></li>
<li><a href="/how-to-run-your-first-classifier-in-weka/">Your First Classifier in Weka</a></li>
<li><a href="/arima-for-time-series-forecasting-with-python/">Your First Time Series Forecasting Project</a></li>
</ul></div></div></aside><!-- /#sidebar -->
</div><!-- /#main-sidebar-container -->
</div><!-- /#content -->
<footer class="col-full" id="footer">
<div class="col-left" id="copyright">
<p>© 2018 Machine Learning Mastery. All Rights Reserved. </p> </div>
<div class="col-right" id="credit">
<p></p><p>
<a href="/privacy/">Privacy</a> | 
<a href="/disclaimer/">Disclaimer</a> | 
<a href="/terms-of-service/">Terms</a> | 
<a href="/contact/">Contact</a>
</p> </div>
</footer>
</div><!-- /#inner-wrapper -->
</div><!-- /#wrapper -->
<div class="fix"></div><!--/.fix-->
<!-- Drip -->
<script type="text/javascript">
  var _dcq = _dcq || [];
  var _dcs = _dcs || {};
  _dcs.account = '9556588';

  (function() {
    var dc = document.createElement('script');
    dc.type = 'text/javascript'; dc.async = true;
    dc.src = '//tag.getdrip.com/9556588.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(dc, s);
  })();
</script>
<!-- end Drip --><!-- Woo Tabs Widget -->
<script type="text/javascript">
jQuery(document).ready(function(){
	// UL = .wooTabs
	// Tab contents = .inside

	var tag_cloud_class = '#tagcloud';

	//Fix for tag clouds - unexpected height before .hide()
	var tag_cloud_height = jQuery( '#tagcloud').height();

	jQuery( '.inside ul li:last-child').css( 'border-bottom','0px' ); // remove last border-bottom from list in tab content
	jQuery( '.wooTabs').each(function(){
		jQuery(this).children( 'li').children( 'a:first').addClass( 'selected' ); // Add .selected class to first tab on load
	});
	jQuery( '.inside > *').hide();
	jQuery( '.inside > *:first-child').show();

	jQuery( '.wooTabs li a').click(function(evt){ // Init Click funtion on Tabs

		var clicked_tab_ref = jQuery(this).attr( 'href' ); // Strore Href value

		jQuery(this).parent().parent().children( 'li').children( 'a').removeClass( 'selected' ); //Remove selected from all tabs
		jQuery(this).addClass( 'selected' );
		jQuery(this).parent().parent().parent().children( '.inside').children( '*').hide();

		jQuery( '.inside ' + clicked_tab_ref).fadeIn(500);

		 evt.preventDefault();

	})
})
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/comment-reply.min.js?ver=4.9.8" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var wpcf7 = {"apiSettings":{"root":"https:\/\/machinelearningmastery.com\/wp-json\/contact-form-7\/v1","namespace":"contact-form-7\/v1"},"recaptcha":{"messages":{"empty":"Please verify that you are not a robot."}},"cached":"1"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/js/scripts.js?ver=5.0.5" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/wp-embed.min.js?ver=4.9.8" type="text/javascript"></script>
<script async="async" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/akismet/_inc/form.js?ver=4.1" type="text/javascript"></script>
</body>
</html>